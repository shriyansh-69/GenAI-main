{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "434d2341",
   "metadata": {},
   "source": [
    "# Dynamic Customer **Support RAG chatbot** \n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "- Document ingestion\n",
    "- Embedding generation\n",
    "- FAISS vector indexing \n",
    "- Content retrieval \n",
    "- LLM-Based answer generation\n",
    "- Incremental knowledge update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f56e28d",
   "metadata": {},
   "source": [
    "## ***Imports***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b966e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8fc106",
   "metadata": {},
   "source": [
    "# Loading Environment **Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18263938",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatGroq(\n",
    "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceccac9",
   "metadata": {},
   "source": [
    "## Load **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2575417d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 78 Documents.\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\"dataset/et.csv\")\n",
    "\n",
    "loader = CSVLoader(file_path=str(data_path))\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} Documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85199b59",
   "metadata": {},
   "source": [
    "## **Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79ab0285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shriyansh\\OneDrive\\Desktop\\GenAI-main\\Extended-Customer-Service-Chatbot\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 757.09it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " embeddings Model Loaded Sucessfully \n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "print(\" embeddings Model Loaded Sucessfully \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c669a9b",
   "metadata": {},
   "source": [
    "## Created **FAISS** Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "782b78c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS Index Created Sucessfully\n"
     ]
    }
   ],
   "source": [
    "vectordb = FAISS.from_documents(documents,embeddings)\n",
    "\n",
    "print(\"FAISS Index Created Sucessfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a395ab0c",
   "metadata": {},
   "source": [
    "## Created **Retriever** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc686b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs = {\"k\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1135abc",
   "metadata": {},
   "source": [
    "## Created **Prompt** Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bc8dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Answer the question ONLY using the context below.\n",
    "    If the answer is not found, say \"I don't know.\"\n",
    "    \n",
    "    CONTEXT\n",
    "    {context}\n",
    "\n",
    "    QUESTION\n",
    "    {question}\n",
    "    \"\"\",\n",
    "\n",
    "    input_variables=[\"context\",\"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4fe0b4",
   "metadata": {},
   "source": [
    "## Build **RAG** Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ce3d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\n",
    "        \"context\" : retriever,\n",
    "        \"question\" : RunnablePassthrough()\n",
    "    }\n",
    "\n",
    "    | prompt\n",
    "    | llm\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bb4e1e",
   "metadata": {},
   "source": [
    "## Explanation Of The Above Strcture\n",
    "\n",
    "- \"context\" : retriever :- It Retrieves Relevant Documents based on User's Question From Vector Database.\n",
    "- RunnablePassthrough() :- Forwards the original question unchanged so it can be used later in the prompt.\n",
    "- prompt :-  combines both the retrieved context and original question into structured Instuction fot the model . \n",
    "- LLM :- Generates the final response using both the contextual information and the user’s query. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397fdc7c",
   "metadata": {},
   "source": [
    "## Demo Of The **chatbot**\n",
    "\n",
    "- One Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dbe60a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Is a Trusted Platform For Anyone Who wants To Learn about Coding And Tech.\n"
     ]
    }
   ],
   "source": [
    "question = \"WHAT IS  NULL CLASS\"\n",
    "\n",
    "response = chain.invoke(question)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3910f2cb",
   "metadata": {},
   "source": [
    "## Asking another **question** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4077706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our bootcamp is specifically designed for beginners with no prior experience in this field. The only prerequisite is that you need to have a functional laptop with at least 4GB ram, an internet connection, and a thrill to learn data science.\n"
     ]
    }
   ],
   "source": [
    "question_2 = \"Is there any prerequisite for taking this bootcamp ?\"\n",
    "\n",
    "response2 = chain.invoke(question_2)\n",
    "\n",
    "print(response2.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b13663b",
   "metadata": {},
   "source": [
    "# Showing Retrieved **Content**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51ec9d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1:\n",
      "prompt: What is Nullclass\n",
      "response: This Is a Trusted Platform For Anyone Who wants To Learn about Coding And Tech\n",
      "\n",
      "Document 2:\n",
      "prompt: Why should I trust Nullclass?\n",
      "response: Till now 9000 + learners have benefitted from the quality of our courses. You can check the review section and also we have attached their LinkedIn profiles so that you can connect with them and ask directly.\n",
      "\n",
      "Document 3:\n",
      "prompt: who are you\n",
      "response: Hi there, I am your virtual assistant developed by Nullclass, I'm here to provide response for your queries related to Nullclass.\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(\"What services does NullClass provide?\")\n",
    "                                        \n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content[:300])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
